{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison Lab\n",
    "\n",
    "In this lab we will compare the performance of all the models we have learned about so far, using the car evaluation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data\n",
    "\n",
    "The [car evaluation dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/car/) is in the assets/datasets folder. By now you should be very familiar with this dataset.\n",
    "\n",
    "1. Load the data into a pandas dataframe\n",
    "- Encode the categorical features properly: define a map that preserves the scale (assigning smaller numbers to words indicating smaller quantities)\n",
    "- Separate features from target into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>acceptability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety acceptability\n",
       "0  vhigh  vhigh     2       2    small    low         unacc\n",
       "1  vhigh  vhigh     2       2    small    med         unacc\n",
       "2  vhigh  vhigh     2       2    small   high         unacc\n",
       "3  vhigh  vhigh     2       2      med    low         unacc\n",
       "4  vhigh  vhigh     2       2      med    med         unacc"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../assets/datasets/car.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2' '4' 'more']\n",
      "['vhigh' 'high' 'med' 'low']\n",
      "['2' '3' '4' '5more']\n",
      "['low' 'med' 'high']\n",
      "['unacc' 'acc' 'vgood' 'good']\n",
      "['vhigh' 'high' 'med' 'low']\n",
      "['small' 'med' 'big']\n"
     ]
    }
   ],
   "source": [
    "print(df.persons.unique())\n",
    "print(df.buying.unique())\n",
    "print(df.doors.unique())\n",
    "print(df.safety.unique())\n",
    "print(df.acceptability.unique())\n",
    "print(df.maint.unique())\n",
    "print(df.lug_boot.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map1 = {\"low\":1, \n",
    "        \"med\":2, \n",
    "        \"high\":3, \n",
    "        \"vhigh\":4}\n",
    "map2 = {\"small\":1, \n",
    "        \"med\":2,\n",
    "        \"big\":3}\n",
    "map3 = {\"unacc\":1, \n",
    "        \"acc\":2, \n",
    "        \"good\":3, \n",
    "        \"vgood\":4}\n",
    "map4 = {\"2\":2,\n",
    "        \"4\":4,\n",
    "        \"more\":5}\n",
    "map5 = {\"2\":2, \n",
    "        \"3\":3, \n",
    "        \"4\":4,\n",
    "        \"5more\": 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety\n",
       "0       4      4      2        2         1       1\n",
       "1       4      4      2        2         1       2\n",
       "2       4      4      2        2         1       3\n",
       "3       4      4      2        2         2       1\n",
       "4       4      4      2        2         2       2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [c for c in df.columns if c != \"acceptability\"]\n",
    "dfn = df.copy()\n",
    "\n",
    "dfn.buying = df.buying.map(map1)\n",
    "dfn.maint = df.maint.map(map1)\n",
    "dfn.lug_boot = df.lug_boot.map(map2)\n",
    "dfn.persons = df.persons.map(map4)\n",
    "dfn.doors = df.doors.map(map5)\n",
    "dfn.safety = df.safety.map(map1)\n",
    "dfn.acceptability = df.acceptability.map(map3)\n",
    "\n",
    "X = dfn[features]\n",
    "y = dfn['acceptability']\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      "buying           1728 non-null int64\n",
      "maint            1728 non-null int64\n",
      "doors            1728 non-null int64\n",
      "persons          1728 non-null int64\n",
      "lug_boot         1728 non-null int64\n",
      "safety           1728 non-null int64\n",
      "acceptability    1728 non-null int64\n",
      "dtypes: int64(7)\n",
      "memory usage: 94.6 KB\n"
     ]
    }
   ],
   "source": [
    "dfn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Useful preparation\n",
    "\n",
    "Since we will compare several models, let's write a couple of helper functions.\n",
    "\n",
    "1. Separate X and y between a train and test set, using 30% test set, random state = 42\n",
    "    - make sure that the data is shuffled and stratified\n",
    "2. Define a function called `evaluate_model`, that trains the model on the train set, tests it on the test, calculates:\n",
    "    - accuracy score\n",
    "    - confusion matrix\n",
    "    - classification report\n",
    "3. Initialize a global dictionary to store the various models for later retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.3, random_state = 42, stratify =y)\n",
    "\n",
    "\n",
    "def evaluate_model(model):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    a = accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    cm= confusion_matrix(y_test,y_pred)\n",
    "    cr = classification_report(y_test,y_pred)\n",
    "    \n",
    "    print cm\n",
    "    print cr\n",
    "    \n",
    "    return a\n",
    "all_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.a KNN\n",
    "\n",
    "Let's start with `KNeighborsClassifier`.\n",
    "\n",
    "1. Initialize a KNN model\n",
    "- Evaluate it's performance with the function you previously defined\n",
    "- Find the optimal value of K using grid search\n",
    "    - Be careful on how you perform the cross validation in the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[354   9   0   0]\n",
      " [  8 107   0   0]\n",
      " [  0   9  11   1]\n",
      " [  0   2   0  18]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.98      0.98      0.98       363\n",
      "          2       0.84      0.93      0.88       115\n",
      "          3       1.00      0.52      0.69        21\n",
      "          4       0.95      0.90      0.92        20\n",
      "\n",
      "avg / total       0.95      0.94      0.94       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "a = evaluate_model(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "params = {\"n_neighbors\" : range(2,60)}\n",
    "\n",
    "gsknn = GridSearchCV(KNeighborsClassifier(),\n",
    "                    params, n_jobs = -1,\n",
    "                    cv = KFold(len(y), n_folds = 3, shuffle =True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=1728, n_folds=3, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsknn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsknn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94618055555555558"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsknn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsknn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[354   9   0   0]\n",
      " [  8 107   0   0]\n",
      " [  0   9  11   1]\n",
      " [  0   2   0  18]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.98      0.98      0.98       363\n",
      "          2       0.84      0.93      0.88       115\n",
      "          3       1.00      0.52      0.69        21\n",
      "          4       0.95      0.90      0.92        20\n",
      "\n",
      "avg / total       0.95      0.94      0.94       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a= evaluate_model(gsknn.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_models[\"knn\"] = {\"model\": gsknn.best_estimator_,\n",
    "                    \"score\" : a}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn': {'model': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "             weights='uniform'), 'score': 0.77456647398843925}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.b Bagging + KNN\n",
    "\n",
    "Now that we have found the optimal K, let's wrap `KNeighborsClassifier` in a BaggingClassifier and see if the score improves.\n",
    "\n",
    "1. Wrap the KNN model in a Bagging Classifier\n",
    "- Evaluate performance\n",
    "- Do a grid search only on the bagging classifier params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.17.1'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap the KNN model in a Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[353  10   0   0]\n",
      " [ 10 103   2   0]\n",
      " [  0   8  12   1]\n",
      " [  0   4   0  16]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.97      0.97      0.97       363\n",
      "          2       0.82      0.90      0.86       115\n",
      "          3       0.86      0.57      0.69        21\n",
      "          4       0.94      0.80      0.86        20\n",
      "\n",
      "avg / total       0.93      0.93      0.93       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import  BaggingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "cv = StratifiedKFold(y, n_folds=3, shuffle=True, random_state=41)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "bgClass = BaggingClassifier(knn)\n",
    "a = evaluate_model(bgClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgClass.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaggingClassifier' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-d309b47a2572>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbgClass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaggingClassifier' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "bgClass.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaggingClassifier' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-7f3d46bfa4d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbgClass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaggingClassifier' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "bgClass.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a= evaluate_model(bgClass.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a grid search only on the bagging classifier params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bagging_params ={\"n_estimators\": [10,20],\n",
    "                \"max_samples\":[0.7,1.0],\n",
    "                \"max_features\":[0.7,1.0],\n",
    "                \"bootstrap_features\":[True,False]}\n",
    "gsbaggingknn = GridSearchCV(bgClass,\n",
    "                    bagging_params, n_jobs = -1,\n",
    "                    cv = KFold(len(y), n_folds = 3, shuffle =True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=1728, n_folds=3, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [10, 20], 'max_samples': [0.7, 1.0], 'bootstrap_features': [True, False], 'max_features': [0.7, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsbaggingknn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=1728, n_folds=3, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [10, 20], 'max_samples': [0.7, 1.0], 'bootstrap_features': [True, False], 'max_features': [0.7, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsbaggingknn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap_features': False,\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 0.7,\n",
       " 'n_estimators': 20}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsbaggingknn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94965277777777779"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsbaggingknn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=20, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsbaggingknn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[356   7   0   0]\n",
      " [  4 110   1   0]\n",
      " [  0   7  14   0]\n",
      " [  0   3   1  16]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.99      0.98      0.98       363\n",
      "          2       0.87      0.96      0.91       115\n",
      "          3       0.88      0.67      0.76        21\n",
      "          4       1.00      0.80      0.89        20\n",
      "\n",
      "avg / total       0.96      0.96      0.96       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a= evaluate_model(gsbaggingknn.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression\n",
    "\n",
    "Let's see if logistic regression performs better\n",
    "\n",
    "1. Initialize LR and test on Train/Test set\n",
    "- Find optimal params with Grid Search\n",
    "- See if Bagging improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[347  11   4   1]\n",
      " [ 59  53   3   0]\n",
      " [  5  15   1   0]\n",
      " [  0  19   0   1]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.84      0.96      0.90       363\n",
      "          2       0.54      0.46      0.50       115\n",
      "          3       0.12      0.05      0.07        21\n",
      "          4       0.50      0.05      0.09        20\n",
      "\n",
      "avg / total       0.73      0.77      0.74       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "a = evaluate_model(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "params = {\"n_neighbors\" : range(2,60)}\n",
    "\n",
    "gsknn = GridSearchCV(KNeighborsClassifier(),\n",
    "                    params, n_jobs = -1,\n",
    "                    cv = KFold(len(y), n_folds = 3, shuffle =True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gsknn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bgknn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bgknn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Decision Trees\n",
    "\n",
    "Let's see if Decision Trees perform better\n",
    "\n",
    "1. Initialize DT and test on Train/Test set\n",
    "- Find optimal params with Grid Search\n",
    "- See if Bagging improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "\n",
    "cv = StratifiedKFold(y, n_folds=3, shuffle=True, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's initialize a Decision Tree Classifier and evaluate its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(class_weight='balanced')\n",
    "bdt = BaggingClassifier(DecisionTreeClassifier())\n",
    "s = cross_val_score(dt, X, y, cv=cv, n_jobs=-1)\n",
    "print \"{} Score:\\t{:0.3} ± {:0.3}\".format(\"Decision Tree\", s.mean().round(3), s.std().round(3))\n",
    "score(bdt, \"Bagging DT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Support Vector Machines\n",
    "\n",
    "Let's see if SVM perform better\n",
    "\n",
    "1. Initialize SVM and test on Train/Test set\n",
    "- Find optimal params with Grid Search\n",
    "- See if Bagging improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Random Forest & Extra Trees\n",
    "\n",
    "Let's see if Random Forest and Extra Trees perform better\n",
    "\n",
    "1. Initialize RF and ET and test on Train/Test set\n",
    "- Find optimal params with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "bdt = BaggingClassifier(DecisionTreeClassifier())\n",
    "rf = RandomForestClassifier(class_weight='balanced', n_jobs=-1)\n",
    "et = ExtraTreesClassifier(class_weight='balanced', n_jobs=-1)\n",
    "\n",
    "def score(model, name):\n",
    "    s = cross_val_score(model, X, y, cv=cv, n_jobs=-1)\n",
    "    print \"{} Score:\\t{:0.3} ± {:0.3}\".format(name, s.mean().round(3), s.std().round(3))\n",
    "\n",
    "score(dt, \"Decision Tree\")\n",
    "score(bdt, \"Bagging DT\")\n",
    "score(rf, \"Random Forest\")\n",
    "score(et, \"Extra Trees\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model comparison\n",
    "\n",
    "Let's compare the scores of the various models.\n",
    "\n",
    "1. Do a bar chart of the scores of the best models. Who's the winner on the train/test split?\n",
    "- Re-test all the models using a 3 fold stratified shuffled cross validation\n",
    "- Do a bar chart with errorbars of the cross validation average scores. is the winner the same?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "We have encoded the data using a map that preserves the scale.\n",
    "Would our results have changed if we had encoded the categorical data using `pd.get_dummies` or `OneHotEncoder`  to encode them as binary variables instead?\n",
    "\n",
    "1. Repeat the analysis for this scenario. Is it better?\n",
    "- Experiment with other models or other parameters, can you beat your classmates best score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
